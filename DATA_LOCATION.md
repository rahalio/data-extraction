# Data Storage Location

## ğŸ“ Primary Data Directory

All extracted and processed data is stored in:

```
~/Documents/data-extraction-data/
```

## ğŸ“ Directory Structure

```
data-extraction-data/
â”œâ”€â”€ linkedin-salesnav/      # LinkedIn Sales Navigator data
â”‚   â”œâ”€â”€ raw/               # Original JSON exports (30 files, 1.6MB)
â”‚   â”œâ”€â”€ processed/         # Generated CSV files
â”‚   â””â”€â”€ archives/          # Backup/historical data
â”‚
â”œâ”€â”€ apollo-io/             # Apollo.io data
â”‚   â”œâ”€â”€ raw/              # Original exports
â”‚   â””â”€â”€ processed/        # Generated files
â”‚
â”œâ”€â”€ exports/              # Final deliverables
â””â”€â”€ sample-data/          # Test data for development
```

## ğŸš€ Usage Examples

### Process LinkedIn SalesNav Data

```bash
# Process raw JSON files to CSV
python3 workflows/linkedin_salesnav_pipeline.py \
  --input-dir ~/Documents/data-extraction-data/linkedin-salesnav/raw \
  --output-dir ~/Documents/data-extraction-data/linkedin-salesnav/processed
```

### Combine Multiple JSON Files

```bash
python3 src/combiners/json_merger.py \
  --input-dir ~/Documents/data-extraction-data/linkedin-salesnav/raw \
  --output ~/Documents/data-extraction-data/linkedin-salesnav/processed/combined.json
```

### Convert JSON to CSV

```bash
python3 src/converters/linkedin_to_csv_enhanced.py \
  --input-dir ~/Documents/data-extraction-data/linkedin-salesnav/raw \
  --output ~/Documents/data-extraction-data/linkedin-salesnav/processed/companies.csv
```

## ğŸ”’ Data Protection

- âœ… All real data is stored **outside** the git repository
- âœ… Protected by comprehensive `.gitignore` patterns
- âœ… No risk of accidental public commits
- âœ… Backup location: `~/Documents/data-extraction-data/linkedin-salesnav/archives/`

## ğŸ“Š Current Data Inventory

### LinkedIn Sales Navigator

- **Raw Files:** 30 JSON files
- **Total Size:** ~1.6 MB
- **Records:** 750 companies
- **Last Updated:** October 31, 2025

## ğŸ“ Best Practices

1. **Keep raw data intact** - Always preserve original JSON files
2. **Version processed outputs** - Add dates to processed files
3. **Regular backups** - Archive important extracts
4. **Document sources** - Note where data came from and when

## ğŸ”„ Workflow

```
Raw Data (JSON)
    â†“
[json_merger.py] â†’ Combined JSON
    â†“
[linkedin_to_csv_enhanced.py] â†’ Processed CSV
    â†“
Export to clients/analysis tools
```

## ğŸ’¡ Tips

- Use `--verbose` flag for detailed logging
- Check the `processed/` folder before overwriting
- Archive old exports before processing new data
- Use the `--keep-combined` flag to retain intermediate files
